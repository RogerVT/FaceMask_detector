{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Facemask detection dataset\n",
    "\n",
    "The following code converts the nearly 11.8 images from this [kaggle dataset](https://www.kaggle.com/ashishjangra27/face-mask-12k-images-dataset) to a Hierarchical Data Format 5 file in order to be processed for the neural network modeled for this project. The code requires h5py, PIL and permissions form the OS library to function properly. This notebook should be run in the same folder as the images dataset. \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os \n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "source": [
    "First, the images are normalized to a square 64x64px size: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['./Test/WithMask/', './Test/WithoutMask⁄', './Train/WithMask/', './Train/WithoutMask/', './Validation/WithMask/', './Validation/WithoutMask/']\n",
    "\n",
    "for carpet in folders:\n",
    "    dirs = os.listdir(carpet)\n",
    "    for item in dirs:\n",
    "        path = os.path.join(carpet, item)\n",
    "        temp_img = Image.open(path)\n",
    "        temp_img = temp_img.resize((64,64))\n",
    "        temp_img.save(path)\n"
   ]
  },
  {
   "source": [
    "Después las imágenes fueron procesadas con el siguiente proceso:\n",
    "Then the images are processed accordingly: \n",
    "+ Images are open and converted into a numpy array.\n",
    "+ The array is added to a number flag which indicates the image class (1-mask, 0-nonmask). The array is then added to an array of arrays. \n",
    "+ This array of arrays is then converted into a numpy array and randomly shuffled. \n",
    "+ Two arrays are formed from this numpy array and then integrated as datasets into the final .h5 file. \n",
    "+ Este arreglo después es añadido a un arreglo con un flag que indica si es una imagen con máscara o no (1 para máscara, 0 para no-máscara). Este arreglo es añadido a un arreglo de arreglos.\n",
    "\n",
    "The dataset used to train, test and validate the model were trimmed into 500, 100, 100 sets accordingly. This decision was due to technical restrictions. If you want to build a bigger dataset, just remove the if() -> instruction into each cell or change the target value. \n",
    "    \n",
    "**train_data.h5** :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archivos en la carpeta ./Train/WithMask/ : 5000\n"
     ]
    }
   ],
   "source": [
    "dir_name = './Train/WithMask/'\n",
    "img_set = []\n",
    "act_dir = os.listdir(dir_name)\n",
    "train_i = 0\n",
    "print('Files in dir ' + dir_name + ' : ' + str(len(act_dir)))\n",
    "for items in act_dir:\n",
    "    if(train_i == 500):\n",
    "        break\n",
    "    path = os.path.join(dir_name, items)\n",
    "    temp_img = np.array(Image.open(path))\n",
    "    img_set.append([temp_img, 1])\n",
    "    train_i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archivos en la carpeta ./Train/WithoutMask/ : 5000\n"
     ]
    }
   ],
   "source": [
    "dir_name2 = './Train/WithoutMask/'\n",
    "act_dir2 = os.listdir(dir_name2)\n",
    "train_i2 = 0\n",
    "print('Files in dir  ' + dir_name2 + ' : ' + str(len(act_dir2)))\n",
    "for items in act_dir2:\n",
    "    if(train_i2 == 500):\n",
    "        break\n",
    "    path = os.path.join(dir_name2, items)\n",
    "    temp_img = np.array(Image.open(path))\n",
    "    img_set.append([temp_img, 0])\n",
    "    train_i2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archivos totales: 10000\n"
     ]
    }
   ],
   "source": [
    "print('Total files: ' + str(len(act_dir) + len(act_dir2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Forma del arreglo generado: (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "temp_array = np.array(img_set)\n",
    "print('Shape of array: ' + str(temp_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(temp_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_x = []\n",
    "set_y = []\n",
    "for elem in temp_array:\n",
    "    set_x.append(elem[0])\n",
    "    set_y.append(elem[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tamaño del archivo generado: 12298048 bytes\n"
     ]
    }
   ],
   "source": [
    "save_path = './Train/train_data_1000.h5'\n",
    "ds_file = h5py.File(save_path, 'a')\n",
    "imgs = ds_file.create_dataset('train_set_x', data = np.array(set_x))\n",
    "labels = ds_file.create_dataset('train_set_y', data = np.array(set_y))\n",
    "ds_file.close()\n",
    "print('File size: %d bytes'%os.path.getsize(save_path))"
   ]
  },
  {
   "source": [
    "Para **test_data.h5** se tiene: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archivos en la carpeta ./Test/WithMask/ : 483\n"
     ]
    }
   ],
   "source": [
    "dir_name = './Test/WithMask/'\n",
    "img_set = []\n",
    "act_dir = os.listdir(dir_name)\n",
    "test_i = 0\n",
    "print('Files in dir  ' + dir_name + ' : ' + str(len(act_dir)))\n",
    "for items in act_dir:\n",
    "    if(test_i == 50):\n",
    "        break\n",
    "    path = os.path.join(dir_name, items)\n",
    "    temp_img = np.array(Image.open(path))\n",
    "    img_set.append([temp_img, 1])\n",
    "    test_i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archivos en la carpeta ./Test/WithoutMask/ : 509\n"
     ]
    }
   ],
   "source": [
    "dir_name2 = './Test/WithoutMask/'\n",
    "act_dir2 = os.listdir(dir_name2)\n",
    "test_i2 = 0\n",
    "print('Files in dir ' + dir_name2 + ' : ' + str(len(act_dir2)))\n",
    "for items in act_dir2:\n",
    "    if(test_i2 == 50):\n",
    "        break\n",
    "    path = os.path.join(dir_name2, items)\n",
    "    temp_img = np.array(Image.open(path))\n",
    "    img_set.append([temp_img, 0])\n",
    "    test_i2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archivos totales: 992\n"
     ]
    }
   ],
   "source": [
    "print('Total files: ' + str(len(act_dir) + len(act_dir2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Forma del arreglo generado: (100, 2)\n"
     ]
    }
   ],
   "source": [
    "temp_array = np.array(img_set)\n",
    "print('Shape of array: ' + str(temp_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(temp_array)\n",
    "set_x = []\n",
    "set_y = []\n",
    "for elem in temp_array:\n",
    "    set_x.append(elem[0])\n",
    "    set_y.append(elem[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tamaño del archivo generado: 1231648 bytes\n"
     ]
    }
   ],
   "source": [
    "save_path = './Test/test_data_100.h5'\n",
    "ds_file = h5py.File(save_path, 'a')\n",
    "imgs = ds_file.create_dataset('test_set_x', data = np.array(set_x))\n",
    "labels = ds_file.create_dataset('test_set_y', data = np.array(set_y))\n",
    "ds_file.close()\n",
    "print('File size: %d bytes'%os.path.getsize(save_path))"
   ]
  },
  {
   "source": [
    "Para validation_data.h5 se tiene:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archivos en la carpeta ./Validation/WithMask/ : 400\n"
     ]
    }
   ],
   "source": [
    "dir_name = './Validation/WithMask/'\n",
    "img_set = []\n",
    "act_dir = os.listdir(dir_name)\n",
    "val_i = 0\n",
    "print('Files in dir  ' + dir_name + ' : ' + str(len(act_dir)))\n",
    "for items in act_dir:\n",
    "    if(val_i == 50):\n",
    "        break\n",
    "    path = os.path.join(dir_name, items)\n",
    "    temp_img = np.array(Image.open(path))\n",
    "    img_set.append([temp_img, 1])\n",
    "    val_i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archivos en la carpeta ./Validation/WithoutMask/ : 400\n"
     ]
    }
   ],
   "source": [
    "dir_name2 = './Validation/WithoutMask/'\n",
    "act_dir2 = os.listdir(dir_name2)\n",
    "val_2 = 0\n",
    "print('Files in dir  ' + dir_name2 + ' : ' + str(len(act_dir2)))\n",
    "for items in act_dir2:\n",
    "    if(val_2 == 50):\n",
    "        break\n",
    "    path = os.path.join(dir_name2, items)\n",
    "    temp_img = np.array(Image.open(path))\n",
    "    img_set.append([temp_img, 0])\n",
    "    val_2+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archivos totales: 800\n"
     ]
    }
   ],
   "source": [
    "print('Total files: ' + str(len(act_dir) + len(act_dir2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Forma del arreglo generado: (100, 2)\n"
     ]
    }
   ],
   "source": [
    "temp_array = np.array(img_set)\n",
    "print('Shape of array: ' + str(temp_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(temp_array)\n",
    "set_x = []\n",
    "set_y = []\n",
    "for elem in temp_array:\n",
    "    set_x.append(elem[0])\n",
    "    set_y.append(elem[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tamaño del archivo generado: 1231648 bytes\n"
     ]
    }
   ],
   "source": [
    "save_path = './Validation/validation_100.h5'\n",
    "ds_file = h5py.File(save_path, 'a')\n",
    "imgs = ds_file.create_dataset('validation_set_x', data = np.array(set_x))\n",
    "labels = ds_file.create_dataset('validation_set_y', data = np.array(set_y))\n",
    "ds_file.close()\n",
    "print('File size: %d bytes'%os.path.getsize(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}